# Sub-Clustering for Class Distance Recalculation in Long-Tailed Drug Discovery

### Overview

In the real world, long-tailed data distributions are prevalent, making it challenging for models to effectively learn and classify tail classes. However, we discover that in the field of drug chemistry, certain tail classes exhibit higher identifiability during training due to their unique molecular structural featuresâ€”a finding that significantly contrasts with the conventional understanding that tail classes are generally difficult to identify. Existing imbalance learning methods, such as resampling and cost-sensitive reweighting, overly rely on sample quantity priors, causing models to excessively focus on tail classes at the expense of head class performance. To address this issue, we propose a novel method that breaks away from the traditional static evaluation paradigm based on sample size. Instead, we establish a dynamical inter-class separability metric using feature distances between different classes. Specifically, we employ a sub-clustering contrastive learning approach to thoroughly learn the embedding features of each class. and we dynamically compute the distances between class embeddings to capture the relative positional evolution of samples from different classes in the feature space, thereby rebalancing the weights of the classification loss function. We conducted experiments on multiple existing longtailed drug datasets and achieved competitive results by improving the accuracy of tail classes without compromising the performance of dominant classes.



### Installation

#### Using `conda`

```bash
conda env create -f environment.yml
conda activate LTDD
```

### Dataset

In this paper, we use three long-tailed dataset (HIV, SBAP, USPTO50k), and provide two different split method ( random split, standard split).

The initial data is SMILES-based. The save path is "./data/dataset name/dataset name.tab". Example: "./data/HIV/hiv.tab".

With dgl library, we transform the data into graph-based data, then spliting it into train set validate set and test set. The save path is "./data/dataset name/split method/dataset name_split method_mode.bin". Example: "./data/HIV/random/HIV_random_train.bin".


### Running Examples

```bash
python main.py --dataset SBAP --split random
python main.py --dataset HIV --split standard
python main.py --dataset USPTO50k --split standrad
```
